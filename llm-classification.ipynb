{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3fdf9b",
   "metadata": {},
   "source": [
    "# Using LLMs for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082b69d",
   "metadata": {},
   "source": [
    "## Libraries Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a40e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b958aa0",
   "metadata": {},
   "source": [
    "## Extract from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03233782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/PURE_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e544e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3cd2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Requirement':'text', 'Name of Doc': 'source', 'Req/Not Req': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9d80998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = np.where(df['label'] == 'Req', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0427d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>System Initialization performs those functions...</td>\n",
       "      <td>nasa x38.doc</td>\n",
       "      <td>Req</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whenever a power-on reset occurs, System Initi...</td>\n",
       "      <td>nasa x38.doc</td>\n",
       "      <td>Req</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As part of System Initialization , the Boot RO...</td>\n",
       "      <td>nasa x38.doc</td>\n",
       "      <td>Req</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>System Initialization shall [SRS014] initiate ...</td>\n",
       "      <td>nasa x38.doc</td>\n",
       "      <td>Req</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>System Initialization shall [SRS292] enable an...</td>\n",
       "      <td>nasa x38.doc</td>\n",
       "      <td>Req</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        source label  y\n",
       "0  System Initialization performs those functions...  nasa x38.doc   Req  1\n",
       "1  Whenever a power-on reset occurs, System Initi...  nasa x38.doc   Req  1\n",
       "2  As part of System Initialization , the Boot RO...  nasa x38.doc   Req  1\n",
       "3  System Initialization shall [SRS014] initiate ...  nasa x38.doc   Req  1\n",
       "4  System Initialization shall [SRS292] enable an...  nasa x38.doc   Req  1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82401c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a requirements demarcator for software and systems engineering documents. Classify a single sentence as either Requirement or Non-requirement.\n",
    "1. Definition of Requirement\n",
    "    A Requirement contains wording strongly associated with required system behavior or capabilities. It typically includes directive phrases such as:\n",
    "    the system, shall be, should be, must be, will be (referring to the system), system provides, ability to, be able to, the user, can be, at least, shall provide, able to.\n",
    "    A Requirement describes behavior, features, constraints, or capabilities that a system must provide.\n",
    "\n",
    "2. Definition of Non-requirement\n",
    "    A Non-requirement contains wording associated with explanations, descriptions, document text, assumptions, or information that is not specifying mandatory system behavior. It often includes phrases such as:\n",
    "    this document, of the, it is, the same, the library, there is, the requirements, to be (as description), the project, in this, by the.\n",
    "    A Non-requirement provides context, references, assumptions, or descriptions without specifying required system functionality.\n",
    "\n",
    "3. Output format\n",
    "    Only output Requirement or Non-requirement.\n",
    "\n",
    "4. Examples\n",
    "    Sentence: \"The help should be accessible to the users both in the offline and online mode.\"\n",
    "    Label: Requirement\n",
    "\n",
    "    Sentence: \"The interfaces must be made customizable or user-configurable to the extent possible.\"\n",
    "    Label: Requirement\n",
    "\n",
    "    Sentence: \"It is also assumed that the reader has a general understanding of Library services and processes.\"\n",
    "    Label: Non-requirement\n",
    "\n",
    "    Sentence: \"The table of permitted actions in supported file systems is in section 2.2.\"\n",
    "    Label: Non-requirement\n",
    "    \n",
    "Classify the following sentence as Requirement or Non-requirement:\n",
    "    Sentence: \"{sentence}\"\n",
    "    Label:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c4a0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dbfcaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a02dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying:   0%|          | 0/1534 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Classifying: 100%|██████████| 1534/1534 [06:33<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Accuracy: 0.3213820078226858\n",
      "Precision: 0.7575757575757576\n",
      "Recall: 0.023629489603024575\n",
      "F1 Score: 0.045829514207149404\n",
      "AUC: 0.5034113834569744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "preds = []\n",
    "truth = []\n",
    "\n",
    "# iterrows wrapped with tqdm\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Classifying\"):\n",
    "    X = row['text']\n",
    "    y = row['label']\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(sentence=X)\n",
    "    output = classifier(prompt)\n",
    "\n",
    "    raw = output[0]['generated_text']\n",
    "    answer = raw.replace(prompt, \"\").strip()\n",
    "    first_line = answer.splitlines()[0].strip().lower()\n",
    "\n",
    "    if first_line.startswith(\"requirement\"):\n",
    "        preds.append('Req')\n",
    "    else:\n",
    "        preds.append('Not_Req')\n",
    "\n",
    "    truth.append(y)\n",
    "\n",
    "# Convert to binary for metrics\n",
    "binary_preds = [1 if p == 'Req' else 0 for p in preds]\n",
    "binary_truth = [1 if t == 'Req' else 0 for t in truth]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(truth, preds)\n",
    "precision = precision_score(binary_truth, binary_preds)\n",
    "recall = recall_score(binary_truth, binary_preds)\n",
    "f1 = f1_score(binary_truth, binary_preds)\n",
    "auc = roc_auc_score(binary_truth, binary_preds)\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efebd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 10 misclassified examples to improve the prompt.\n"
     ]
    }
   ],
   "source": [
    "# ---- Collect misclassified examples ---- #\n",
    "misclassified = []\n",
    "\n",
    "for sent, true, pred in zip(df[\"text\"], truth, preds):\n",
    "    if true != pred:\n",
    "        misclassified.append((sent, true, pred))\n",
    "\n",
    "# Limit to a few examples for prompt clarity\n",
    "misclassified = misclassified[:10]\n",
    "\n",
    "print(f\"\\nFound {len(misclassified)} misclassified examples to improve the prompt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab970d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_meta_prompt(current_prompt, mistakes):\n",
    "    meta = f\"\"\"\n",
    "You are helping to design a better prompt for a classifier that distinguishes\n",
    "\"Requirement\" vs \"Non-requirement\" in software specification sentences.\n",
    "\n",
    "Here is the CURRENT prompt:\n",
    "\n",
    "<<<BEGIN CURRENT PROMPT>>>\n",
    "{current_prompt}\n",
    "<<<END CURRENT PROMPT>>>\n",
    "\n",
    "Below are example sentences that the classifier FAILED on. Each shows the sentence,\n",
    "its true label, and how the model incorrectly predicted:\n",
    "\n",
    "\"\"\"\n",
    "    for sent, true, pred in mistakes:\n",
    "        meta += f\"\"\"\n",
    "Sentence: \"{sent}\"\n",
    "True label: {true}\n",
    "Model predicted: {pred}\n",
    "\"\"\"\n",
    "\n",
    "    meta += \"\"\"\n",
    "TASK:\n",
    "Using the mistakes and the current instructions, rewrite the classifier prompt so that:\n",
    "- Definitions are clearer\n",
    "- The difference between obligation & description is emphasized\n",
    "- Examples better illustrate edge cases\n",
    "- The output format stays EXACTLY one of: Requirement or Non-requirement\n",
    "- DO NOT return analysis. Return ONLY the new improved full prompt.\n",
    "\n",
    "Return ONLY the improved prompt, nothing else.\n",
    "\"\"\"\n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f6dabac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "meta_prompt = build_meta_prompt(PROMPT_TEMPLATE, misclassified)\n",
    "\n",
    "improved = classifier(meta_prompt, max_new_tokens=800, do_sample=False, temperature=0.0)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc4019a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- IMPROVED PROMPT -----\n",
      "\n",
      "Requirement\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "improved_only = improved.replace(meta_prompt, \"\").strip()\n",
    "\n",
    "print(\"\\n----- IMPROVED PROMPT -----\\n\")\n",
    "print(improved_only)\n",
    "print(\"\\n---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2eb125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
